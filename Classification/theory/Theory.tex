\documentclass[12pt]{article}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{bm}
\newcommand{\betah}{\hat{\bm \beta}}
\newcommand{\betaa}{\bm{\beta}}
\newcommand{\epss}{\bm{\varepsilon}}
%\newcommand{\E}{\mathrm{E}}
%\newcommand{\D}{\mathrm{D}}
\newcommand{\XT}{{\bm{X}}^{\mathrm{T}}}
\newcommand{\X}{\bm{X}}
\newcommand{\y}{\bm{y}}


\begin{document}
	\title{Обучение с учителем. Классификация. Дискриминантный анализ. Логистическая регрессия. Метод опорных векторов. Выбор модели с помощью кросс-валидации. Метод стохастического градиента.}
	\author{Гриненко Юрий}
	\maketitle
	
	\newpage
	\tableofcontents
	\newpage
	
	
	
	
	\section{Классификация}
	
	\begin{itemize}
	\item Имеется случайный вектор признаков $\xi \in \mathbb{R}^p$, дискретная случайная величина $\eta \in \mathcal{G} = \{G_k\}_{k = 1}^K$, метка класса.
	\item $y$ - вектор меток класса, соответствующий матрице признаков $X$;
	\item Задача --- построить классификатор $f : \mathbb{R}^p \rightarrow \mathcal{G}$ по обучающей выборке $X_{train}; y_{train}$, предсказывающий метку класса на контрольной выборке. 
	\end{itemize}
	
	Имеем N реализаций случайного вектора $(\xi, \eta)$. При переходе к выборкам случайные величины заменяются на матрицу наблюдений и на вектор классовой принадлежности соответственно. Строим классификатор
	\begin{eqnarray}\label{Base}  
		f : \mathbb{R}^p \rightarrow \mathcal{G}. 
	\end{eqnarray}
	
	Запишем в форме
	\begin{eqnarray}\label{Base_2}  
		f (x_i, w) = sign (\langle x_i, w \rangle - w_o) = sign \sum_{i=1}^{n} w_i x_i - w_o, 
	\end{eqnarray}
	
	где $w = (w_1, ..., w_n)$ ---- вектор весов, $\langle x_i, w \rangle$ --- скалярное произведение признакового описания объекта на вектор весов. 
	
	Вводим несколько ключевых понятий:
	
	\begin{itemize}
		\item Величина отступа (margin) --- $M_i (w, w_0) = (\langle x_i, w \rangle - w_0) y_i$; чем меньше значение отступа, тем ближе объект к границе классов, соответственно, выше вероятность ошибки (справедливо и обратное);
		\item Функция потерь $\mathcal{L} (a, x)$ --- неотрицательная функция, характеризующая величину ошибки предсказания на объекте $x_i$. Задачу классификации можно свести к минимизации функции потерь;
		\item Функционал качества алгоритма $Q(a, X^n) = \frac{1}{n} \sum_{i = 1}^n \mathcal{L} (a, x_i)$ на выборке $X^n$, также называемый эмпирическим риском.
	\end{itemize} 
	
	\newpage
	
	\begin{figure}[!ht]
		%\vspace{-20mm} % <-- Go crazy here!
		\centering
		\includegraphics[scale=0.8]{img_2}
		\caption{Непрерывные аппроксимации пороговой функции потерь}
		\label{1}
	\end{figure}
	
	Так, вид некоторых Margin-based loss functions:
	
		\begin{itemize}
		\item $Q(M) = (1-M)^2$, квадратичная;
		\item $V(M) = (1-M)$, кусочно-линейная;
		\item $S(M) = 2(1+e^M)^-1$, сигмоидная;
		\item $L(M) = log_2 (1+e^{-M})$, логистичесая;
		\item $E(M) = e^-M$, экспоненциальная.
	\end{itemize} 
	
	\subsection{Качество классификации, метрики}
	
	Матрица ошибок --- способ разбить объекты на четыре категории в зависимости	от комбинации истинного ответа и ответа алгоритма.
	
	\vspace{0.5cm}
	
	\begin{tabular}{l|l|c|c|c}
		\multicolumn{2}{c}{}&\multicolumn{2}{c}{True Class}&\\
		\cline{3-4}
		\multicolumn{2}{c|}{}&Positive&Negative&\multicolumn{1}{c}{Total}\\
		\cline{2-4}
		\multirow{2}{*}{Predicted}& Positive & $TP$ & $FP$ & $TP + FP$\\
		\cline{2-4}
		& Negative & $FN$ & $TN$ & $FN + TN$\\
		\cline{2-4}
		\multicolumn{1}{c}{} & \multicolumn{1}{c}{Total} & \multicolumn{1}{c}{$TP + FN$} & \multicolumn{    1}{c}{$FP + TN$} & \multicolumn{1}{c}{$N$}\\
	\end{tabular}

	\vspace{0.5cm}
	
	Доля правильных ответов для двух классов:
	\begin{eqnarray}\label{Accuracy}  
		Accuracy = \frac{TP + TN}{TP + TN + FP + FN}, 
	\end{eqnarray}

	Может показывать плохо интерпретируемые результаты в случае, если предсказываемые классы в неравномерны, или если стоит задача корректно предсказать только один класс. Лучше интерпретируем метрики, которые показывают точность предсказания одного из классов:
	\begin{eqnarray}\label{Precision}  
		Precision = \frac{TP}{TP+FP}, 
	\end{eqnarray}
	
	Precision --- доля правильно предсказанных объектов класса среди всех, отнесенных алгоритмом к этому классу. Интерпретируется как способность отличать этот класс от других классов.
	\begin{eqnarray}\label{Recall}  
		Recall = \frac{TP}{TP+FN}, 
	\end{eqnarray}
	
	Recall --- доля объектов класса, которую алгоритм классифицировал правильно. Показывает способность алгоритма обнаруживать данный класс вообще. 
	
	
	\section{Дискриминантный анализ}
	
	\subsection{Общий подход к классификации}
	
	Строим классифицирующие функции $f_i$, индивид относится к классу с максимальным значением классифицирующей функции на нем. 
	\begin{eqnarray}\label{classification_1}  
		f(x) = \underset{{Y \in \mathcal{G}}}{\arg \max}  P (Y \vert \xi = x). 
	\end{eqnarray}

	$p_i (x)$ --- условные плотности классов, $\pi_i = P(\eta = Y_i)$ --- априорные вероятности ($\sum_{i=1}^{K} {\pi_{i}} = 1$). По теореме Байеса
	\begin{eqnarray}\label{Bayes}  
		P (Y = i \vert X = x) = \frac {p_i(x) \pi_i}{\sum_{i=1}^{K} p_i (x) \pi_i}, 
	\end{eqnarray}
	
	В качестве классифицирующих функций берем
	\begin{eqnarray}\label{Discr_functions}  
		f_i (x) = \frac {p_i(x) \pi_i}{\sum_{j=1}^{K} p_j (x) \pi_j}. 
	\end{eqnarray}

	Знаменатель будет одинаков у всех таких функций, поэтому можем оставить только значимую часть (числитель).
	
	Априорные вероятности выбираем в зависимости от наших предположений/задачи. С помощью априорных вероятностей формально задавать важность ошибочных классификаций для разных классов. Несколько вариантов выбора:
	
	\begin{itemize}
		\item Равномерно, $\forall i \in 1:k;$ $\pi = 1/k$;
		\item По соотношению в обучающей выборке $\pi_i = n_i / \sum_{j=1}^{k} n_j$;
		\item На основе дополнительной информации (месте проведения исследования, социальных факторах и прочем). 
	\end{itemize}
	
	\subsection{Линейный дискриминантный анализ}
	
	В LDA предполагаем нормальное распределении классов с одинаковой ковариационной матрицей. Классифицирующие функции имеют вид
	\begin{eqnarray}\label{LDA}  
		f_i (x) = \frac {\pi_i}{(2\pi)^{p/2} \vert \Sigma \vert ^{1/2}} \textrm{exp} \left(-\frac{1}{2}(x-\mu_i)^\mathsf{T}\Sigma^{-1}(x-\mu_i)\right), 
	\end{eqnarray}

	и приводятся к виду 
	\begin{eqnarray}\label{LDA}  
		h_i (x) = - \frac{1}{2} \mu_{i}^\mathsf{T} \Sigma^{-1} \mu_i + \mu_{i}^\mathsf{T} \Sigma^{-1}x + log \ \pi_i.
	\end{eqnarray}
	
	\subsection{Канонические переменные} 
	Канонические переменные --- признаки, наилучшим образом разделяющие классы. Задача состоит в нахождении линейного преобразования $\mathbf{Z} = A^T \mathbf{X}$. 
	
	В англоязычной литературе имеет название CDA (Canonical Discriminant Analysis). Результат должен быть примерно как на изображении, сравниваем с PCA.
	
	\smallbreak
	
	\begin{figure}
		\includegraphics[width=\linewidth]{img_1}
		\caption{Canonical Discriminant Analysis and PCA on data}
		\label{2}
	\end{figure}
	
	Вычислим внутриклассовую ковариационную матрицу:
	\begin{eqnarray}\label{CDA_1} 
	\textbf{E}=\frac{1}{n-K}\sum_{i=1}^{K}\sum_{j:y_{j}\prime=Y_{i}}(x_{j}-\hat{\mu}_{i})^{\mathrm{T}}(x_{j}-\hat{\mu}_{i})
	\end{eqnarray}
	
	Вычисляем межклассовую ковариационную матрицу:
	\begin{eqnarray}\label{CDA_2}
	\textbf{H}=\sum_{i=1}^{K}n_{i}(\hat{\mu}_{i}-\hat{\mu})^{\mathrm{T}}(\hat{\mu}_{i}-\mu)
	\end{eqnarray}

	$\zeta=A\xi$ --- новый признак. 
	
	На выборочном языке новые признаки $\textbf{Z}=A^{\mathrm{T}}\textbf{X}$. Выборочная ковариационная матрица новых признаков:
	\begin{eqnarray}\label{CDA_3}
		A^{\mathrm{T}}\textbf{T}A=A^{\mathrm{T}}(\textbf{E}+\textbf{H})A=A^{\mathrm{T}}\textbf{E}A+A^{\mathrm{T}}\textbf{H}A,
	\end{eqnarray}

	$\textbf{T}$ --- total covariance matrix, первое слагаемое --- оценка внутригрупповых отклонений, второе --- межгрупповых. Переходим к обобщенной
	задаче на собственные числа и собственные вектора:
	\begin{eqnarray}\label{CDA_3}
		\frac{A^{\mathrm{T}}\textbf{H}A}{A^{\mathrm{T}}\textbf{E}A}\rightarrow\max_{A}.
	\end{eqnarray}
	
	$\lambda_{1}\geq\lambda_{2}\geq\ldots\geq\lambda_{d}$ --- собственные числа матрицы $\textbf{E}^{-1} \textbf{H}$, $A_1, \dots, A_d$ --- соответствующие
	им собственные вектора. Тогда максимум выше равен $\lambda_{1}$ и достигается на $A_1$. В этих обозначениях, канонические коэффициенты являются собственными векторами матрицы $\mathrm{E}^{-1}\mathrm{H}$, новые признаки $Z_i$ --- канонические переменные, $Z_i$ ортогональны. 
	

	Далее	
	\begin{center}
	$\underset{A,A\perp A_{1}} \max \frac{A^{\mathrm{T}}\textbf{H}A}{A^{\mathrm{T}}\textbf{E}A}=\lambda_{2},$
	\end{center}
	
	Теперь нас интересует, какое количество таких канонических переменных брать. Проверяем гипотезу
	
	\begin{center}
		$H_0 : A_i, i = \ell, \dots, d не описывают отличия.$
	\end{center}

	Используем статистику $\Lambda - prime$ 
	
	\begin{center}
		$\Lambda_{\ell}^{p} = \prod_{i=l}^{d} \frac{1}{1+ \lambda_i}.$
	\end{center}

	Гипотеза может быть представлена как
	
	\begin{center}
	$H_{0}\ :\ \Lambda_{\ell}^{p}=1\Leftrightarrow\lambda_{\ell}=\ldots=\lambda_{d}=0\Leftrightarrow rank \textbf{B}=\ell-1.$
	\end{center}

	Критерий:
	
	\begin{center}
	$t=\Lambda_{\ell}^{p}\sim\Lambda_{\nu_{\mathrm{B}}+(\ell-1),\nu_{\mathrm{W}}-(\ell-1)}.$
	\end{center}

	Другие статистики для проверки гипотезы:
	
	\begin{itemize}
		\item Roy's greatest root: $r_{1}^{2}=\frac{\lambda_{1}}{1+\lambda_{1}}$;
		\item Pillai's trace: $V=trace(\textbf{H}(\textbf{H}+\textbf{E})^{-1})$;
		\item Hotelling-Lawley trace: $V=trace(\textbf{H}\textbf{E}^{-1})$. 
	\end{itemize}

	\subsection{Квадратичный дискриминантный анализ}
	
	Применяем QDA, когда каждый класс имеет многомерное нормальное распрелеление и различные ковариационные матрицы $\Sigma_{i=1}^K$. Классифицирующие функции принимают вид 
	
	\begin{eqnarray}\label{QDA}  
		g_i (x) = log \ f_i(x) = log \ \pi_i - \frac{1}{2} log \vert \Sigma_i \vert - \frac{1}{2} (x^\mathsf{T} - \mu_i) \Sigma_{i}^{-1} (x-\mu_i).
	\end{eqnarray}
	
	\subsection{Регуляризованный дискриминантный анализ, RDA}
	
	RDA представляет собой компромисс между LDA и QDA. Стягиваем ковариации каждого класса к общей матрице
	
	\begin{center}
		$\hat \Sigma_k (\alpha) = \alpha \hat \Sigma_k + (1-\alpha) \hat \Sigma$
	\end{center}

	где $\hat \Sigma_k$ --- оценка из QDA, $\hat \Sigma$ --- оценка из LDA. $\alpha \in [0; 1]$ --- настраиваемый параметр, определяющий, оценивать ли ковариации отдельно $\alpha = 1$ или совместно $\alpha = 0$ (pooled).
	
	Или к единичной матрице
	
	\begin{center}
		$\hat \Sigma_k (\gamma) = \gamma \hat \Sigma_k + (1-\gamma) \hat \sigma \mathbf{I}$
	\end{center}

	Так как RDA это способ регуляризации, он используется при наличие мультиколлинеарности.
	
	
	
		
	\section{Логистическая регрессия}
	
	Вместо предсказания бинарной переменной мы предсказываем непрерывную переменную со значениями на отрезке [0,1] при любых значениях независимых переменных. Из этой ситуации можно выйти так:
	научить линейную модель правильно предсказывать какой-то объект,
	связанный с вероятностью, но с диапазоном значений $(-\infty, \infty)$, и преобразовать ответы модели в вероятность. Используем logit преобразование, логарифм отношения вероятности положительного события к отрицательному $\log(\frac{p}{1-\mathrm{p}})$.
	
	Если ответом модели является $\log(\frac{p}{1-\mathrm{p}})$, то легко получаем, что
	
	$$
	\langle w,x_{i}\rangle=\log(\frac{p}{1-p}),
	$$
	$$
	e^{\langle w,x_{i}\rangle}=\frac{p}{1-p},
	$$
	$$
	\mathrm{p}=\frac{1}{1+e^{-\langle w,x_{i}\}}}.
	$$
	
	Функция в правой части -- сигмоида, и обозначается
	$$
	\sigma(M)=\frac{1}{1+e^{-M}}.
	$$
	
	Сигмоида обладает следующими свойствами, которые нам интересны:
	
	\begin{itemize}
		\item Монотонно возрастает;
		\item отображает всю числовую прямую на интервал (0; 1);
		\item $\sigma(-x) = 1 - \sigma(x)$. 
	\end{itemize}
	
	Функция потерь имеет вид (Оранжевым цветом на рис. 1)
	\begin{eqnarray}\label{LossFunc}
		\mathcal{L}(M_i) = \log(1 + e^{-M}).
	\end{eqnarray}

	\begin{figure}[!ht]
		%\vspace{-20mm} % <-- Go crazy here!
		\centering
		\includegraphics[scale=0.7]{img_3}
		\caption{Логистическая кривая (Сигмоида)}
		\label{3}
	\end{figure}

	\newpage
	
	Таким образом, 
	$$
	p=\sigma(\langle w,X_{i} \rangle).
	$$
	
	Как теперь научиться оптимизировать $w$ так, чтобы модель как можно
	лучше предсказывала логиты? Нужно применить метод максимума
	правдоподобия для распределения Бернулли. Записываем функцию правдоподобия для распределения Бернулли:
	
	$$
	p(y|X,\ w)=\prod_{i=1}^{n} p_{i}^{y_{\mathfrak{i}}}(1-p_{i})^{1-y_{i}}.
	$$
	
	Приводим к логарифмическому виду:
	$$
	\ell(w,X,y)=\sum_{i=1}^{n} (y_{i}\log(p_{i})+(1-y_{i})\log(1-p_{i}))=
	$$
	$$
	=\sum_{i=1}^{n} (y_{i}\log(\sigma(\langle w,x_{i} \rangle))+(1-y_{i})\log(1-\sigma(\langle w,\ x_{i}\rangle))).
	$$
	
	Т.к. справедливо 
	$$
	\sigma(-M)=\frac{1}{1+e^{M}}=\frac{e^{-M}}{e^{-M}+1}=1-\sigma(M),
	$$
		
	то переписываем функцию правдоподобия следующим образом:
	$$
	\ell(w,X,y)=\sum_{i=1}^{n}(y_{i} \log(\sigma(\langle w,x_{i} \rangle))+(1-y_{i})\log(\sigma(-\langle w,\ x_{i}\rangle))).
	$$
	
	Максимизация правдоподобия эквивалентна минимизации функционала, гладко аппроксимирующего эмпирический риск. Чтобы получить функцию потерь, которую мы будем минимизировать, умножаем на $-1$ и получаем
	$$
	\mathcal{L}(w,X,y)=-\sum_{i=1}^{n} (y_{i}\log(\sigma(\langle w,x_{i} \rangle))+(1-y_{i})\log(\sigma(-\langle w,x_{i} \rangle))).
	$$
	
	Методы решения задачи минимизации --- метод стохастического градиента, метод Ньютона-Рафсона.
	
	\subsection{Алгоритм Ньютона-Рафсона}
	
	Существуют различные методы решения нелинейных систем, среди
	которых наиболее популярным и обеспечивающим наилучшую сходимость является
	метод Ньютона–Рафсона. Метод предполагает выбор некоторого начального приближения решения и последовательное его улучшение в ходе выполнения ряда вычислений. Гессиан логарифма правдоподобия
	\begin{eqnarray}\label{Neuton-Raff}
		\frac{\partial^2 \ell(\beta)}{\partial \beta \partial \beta^{\mathrm{T}}} = -\sum_{i = 1}^N x_ix_i^\mathrm{T} p(\mathbf{x}_i; \beta)(1 - p(\mathbf{x}_i; \beta)) = 0.
	\end{eqnarray}

	Пусть $\beta^{old}$ -- некоторое начальное приближение вектора коэффициентов $\beta$, на каждой итерации уточняется следующим образом:
	\begin{align*}
		\beta^{new} = \beta^{old} - \left(\frac{\partial^2 \ell(\beta)}{\partial \beta \partial \beta^{\mathrm{T}}}\right)^{-1}\frac{\partial \ell(\beta)}{\partial \beta},
	\end{align*}
	где производные вычисляются в точке $\beta^{old}$.
	
	$\mathbf{y}$ -- ответы $y_i$, $\mathbf{p} = (p(x_i; \beta^{old}))$, $\mathbf{W}$ -- диагональная матрица размером $N\times N$ весов, где $i$й элемент имеет вид $p(x_i;\beta^{old})(1 - p(x_i; \beta^{old}))$. В матричных обозначениях
	\begin{align*}
		\frac{\partial \ell(\beta)}{\partial \beta} &= \mathbf{X}^\mathrm{T}(\mathbf{y} - \mathbf{p})\\
		\frac{\partial^2 \ell(\beta)}{\partial \beta \partial \beta^{\mathrm{T}}} &= -\mathbf{X}^\mathrm{T}\mathbf{W}\mathbf{X}.
	\end{align*}

	Шаг алгоритма имеет вид
	\begin{multline*}
		\beta^{new} = \beta^{old} + (\mathbf{X}^\mathrm{T}\mathbf{W}\mathbf{X})^{-1}\mathbf{X}^\mathrm{T}(\mathbf{y} - \mathbf{p}) = \\
		= (\mathbf{X}^\mathrm{T}\mathbf{W}\mathbf{X})^{-1}\mathbf{X}^\mathrm{T}\mathbf{W} (\mathbf{X}\beta^{old} + \mathbf{W}^{-1}(\mathbf{y} - \mathbf{p})) = \\
		= (\mathbf{X}^\mathrm{T}\mathbf{W}\mathbf{X})^{-1}\mathbf{X}^\mathrm{T}\mathbf{W}\mathbf{z}.
	\end{multline*}
	Мы переписали итерацию алгоритма как взвешенную регрессию, где в качестве ответа выступает вектор
	\begin{align*}
		\mathbf{z} = \mathbf{X}\beta^{old} + \mathbf{W}^{-1}(\mathbf{y} - \mathbf{p}).
	\end{align*}
	На каждом шаге $\mathbf{p}$ меняется, а вместе с ним и $\mathbf{W}$, $\mathbf{z}$. Этот алгоритм называется iteratively reweighted least squares (IRLS) так как на каждом шаге решается задача
	\begin{align*}
		\beta^{new} = \arg \min_\beta (\mathbf{z} - \mathbf{X}\beta)^\mathrm{T} \mathbf{W}(\mathbf{z} - \mathbf{X}\beta).
	\end{align*}
	
	В качестве начального приближения $\beta^{old}$ можно взять оценки, полученные с помощью обычной линейной регрессии или просто $\beta^{old} = 0$. Сходимость нам не гарантируется, но обычно алгоритм сходится так как логарифм правдоподобия вогнутый.
	
		\subsection{Регуляризация}
	Аналогично обычной линейной регрессии, можно отбирать признаки (осуществлять feature selection) с помощью LASSO (L1) или аналога Ridge Regression (L2). Для этого максимизируем соответственно
	\begin{align*}
		\max_{\beta_0, \beta} \sum\limits_{i = 1}^N \left( y_i(\beta_0 + \beta^\mathrm{T}\mathbf{x}_i) - \log (1 + e^{\beta_0 + \beta^\mathrm{T}\mathbf{x_i}})\right) - \lambda \sum\limits_{j = 1}^p |\beta_j|,
	\end{align*}
	\begin{align*}
		\max_{\beta_0, \beta} \sum\limits_{i = 1}^N \left( y_i(\beta_0 + \beta^\mathrm{T}\mathbf{x}_i) - \log (1 + e^{\beta_0 + \beta^\mathrm{T}\mathbf{x_i}})\right) - \lambda \sum\limits_{j = 1}^p \beta_j^2.
	\end{align*}
	
	Для нахождения точки максимума можно снова использовать алгоритм Ньютона-Рафсона.
	
	\newpage
	
	\section{Метод опорных векторов}
	
	Линейный классификатор, задача классификации в рамках обучения с учителем.
	Имеется выборка $\left\{\left(x_1, y_1\right), \dots, \left(x_n, y_n\right)\right\}$, $x_i\in\mathbb{R}^p$, $y_i\in\left\{-1, 1\right\}$;
	задачей является построение классифицирующего правила $f:\mathbb{R}^p\rightarrow \left\{-1, 1\right\}$. Не накладывается ограничений на распределение.
	
	\subsection{Hard-margin SVM}
	
	Линейный классификатор:
	\begin{eqnarray}
	f\left({x}_i\right)=sign\left(\langle{x}_i,{w}\rangle -w_0\right),
	\end{eqnarray}
	
	Уравнение, описывающее гиперплоскость, разделяющую классы в пространстве $\mathbb{R}$:
	$$
	\langle w, x \rangle = w_0. 
	$$
	
	Предположим, что присутствует линейная разделимость классов, то есть существуют такие значения параметров $w, w_0$, при которых функционал числа ошибок принимает нулевое значение:
	\begin{eqnarray}
	Q(w,\ w_{0})=\sum_{i=1}^{n}[y_{i}(\langle w,\ x_{i}\rangle-w_{0})<0]
	\end{eqnarray}
	
	Вводим критерий оптимальности: максимальное расстояние между двумя гиперплоскостями, параллельных данной и симметрично расположенных относительно неё, при котором между ними не находится ни одна из точек.	
	
	Каждой из двух параллельных гиперплоскостей будет принадлежать некоторое количество точек из соответствующего класса; точки, которые принадлежат одной из гиперплоскостей — будем называть опорными векторами.
	Параметры линейного порогового классификатора определены с точностью до нормировки: алгоритм не изменится, если $w$ и $w_0$ одновременно умножить на одну и ту же положительную константу.  Удобно выбрать её таким образом, чтобы для всех пограничных (ближайших к разделяющей гиперплоскости) объектов $x_i$ из выборки выполнялись условия. Записать можно так:
	
	
	
	$$
	\langle w,\ x_{i}\rangle-w_{0}=y_{i}.
	$$
	
	Сделать это возможно, поскольку при оптимальном положении разделяющей гиперплоскости все пограничные объекты находятся от неё на одинаковом расстоянии. Для всех $x_i$ справедливо
	
	\begin{center}
	$\langle w, x_{i}\rangle-w_{0}\left\{\begin{array}{ll}
	\leq-1, & если i\ y_{i}=-1;\\
	\geq 1, & если i\ y_{i}=+1.
	\end{array}\right.$
	\end{center}
		
	Условие $-1<\langle w, x\rangle-w_{0}<1$ задаёт полосу, разделяющую классы. Ни одна из точек обучающей выборки не может лежать внутри этой полосы. Границами служат две параллельные гиперплоскости с направляющим вектором $w$. При этом сама разделяющая гиперплоскость проходит ровно по середине полосы.
	
	Чтобы разделяющая гиперплоскость как можно дальше отстояла от точек выборки, ширина полосы должна быть максимальной. Пусть $x_-$ и $x_+$ две произвольные точки классов -1 и +1 соответственно, лежащие	на границе полосы. Тогда ширина полосы есть
	
	\begin{align*}
		\langle(x_{+}-x_{-}),\ \frac{w}{\Vert w\Vert}\rangle=\frac{\langle w,x_{+}\rangle-\langle w,x_{-}\rangle}{\Vert w\Vert}=\frac{(w_{0}+1)-(w_{0}-1)}{\Vert w\Vert}=\frac{2}{\Vert w\Vert}.
	\end{align*}
	
	Ширина полосы максимальна, когда норма вектора $w$ минимальна.
	
	Таким образом, когда выборка линейно разделима, имеем следующую задачу --- найти такие значения параметров $w$ и $w_0$, при которых норма вектора $w$ минимальна при условии выше. Это задача квадратичного программирования. 
	
	Построение оптимальной разделяющей гиперплоскости сводится к минимизации квадратичной формы
	$$
	\begin{cases}
		\frac{1}{2}\lVert w \rVert^2 \rightarrow \min\limits_{\boldsymbol{w}};\\
		\left(\langle{x}_i,{w}\rangle - w_0\right)y_i \geq 1. \\
	\end{cases}
	$$
	
	На практике линейно разделимые классы встречаются довольно редко. Поэтому постановку задачи необходимо модифицировать так, чтобы система ограничений была совместна в любой ситуации.
	
	\newpage
			
	\subsection{Soft-margin SVM}
	
	Позволим алгоритму допускать ошибки на обучающих объектах, но при этом постараемся, чтобы ошибок было поменьше. Введём набор дополнительных переменных $\xi > 0$, характеризующих величину ошибки на объектах $x_i, i = 1,... ,n$ ($C$ задает размер штрафа за ошибки.). 
	
	$$ 
	\begin{cases}
		\frac{1}{2}\langle w,\ w\rangle+C\sum_{i=1}^{n}\xi_{i}\rightarrow \underset{w,w_{0},\xi} \min ;\\
		y_{i}(\langle w,\ x_{i}\rangle-w_{0})\geq 1-\xi_{i},\ \forall i;\\
		\xi_{i}\geq 0,\ \forall i.
	\end{cases}
	$$
	
	Помним, что в задачах с двумя классами $Y = {-1, +1}$ отступом (margin) объекта $x_i$ от границы классов называется величина
	$$
	[M_{i}<0]\leq(1-M_{i})_{+}.
	$$
	
	Алгоритм (18) допускает ошибку на объекте $x_i$ только когда отступ $M_i$ отрицателен.  Если $M_i \in (-1, +1)$, то объект $x_i$ попадает внутрь разделяющей полосы. Если $M_i > 1$, то объект  $x_i$ классифицируется правильно, и находится на некотором удалении от разделяющей полосы. Ошибка $\xi_i$ выражается через отступ $M_i$.  
	
	В силу требования минимизации суммы $\sum_{i=1}^{n} \xi_i$, можем записать, что $\xi_i = (1 - M_i)_+$. Задача оказывается эквивалентной безусловной минимизации функционала $Q$, не зависящего от $\xi_i$:
	
	\begin{center}
		$Q(w,\displaystyle \ w_{0})=\sum_{i=1}^{n}(1-M_{i}(w, w_{0}))_{+}+\frac{1}{2C}\Vert w\Vert^{2}\rightarrow\min_{w,w_{0}}$.   
	\end{center}
	
	В силу неравенста $[M_{i}<0]\leq(1-M_{i})_{+}$, функционал $Q$ можно 	рассматривать как верхнюю оценку эмпирического риска (числа ошибочных классификаций объектов обучающей выборки), к которому добавлен регуляризатор $\Vert w\Vert^{2},$ умноженный на параметр регуляризаци $\displaystyle \frac{1}{2\mathrm{C}}.$ 
	
	\begin{figure}[!ht]
		%\vspace{-20mm} % <-- Go crazy here!
		\centering
		\includegraphics[scale=0.8]{img_xxx}
		\caption{Кусочно-линейная аппроксимация пороговой функции потерь: $[M_{i}<0]\leq(1-M_{i})_{+}$}
		\label{4}
	\end{figure}
	
	Замена пороговой функции потерь $[M<0]$ кусочно-линейной верхней оценкой
	$\mathcal{L}(M)=(1-M)_{+}$ делает функцию потерь чувствительной к величине ошибки. Функция потерь $\mathcal{L}(M)$ штрафует объекты за приближение к границе классов. Введение регуляризатора повышает устойчивость решения
	
	Двойственная задача. Запишем функцию Лагранжа:
	$$
	\mathcal{L}(w, w_{0}, \xi;\lambda, \eta)=\frac{1}{2}\Vert w\Vert^{2}+C \sum_{i=1}^{n} \xi-\sum_{i=1}^{n}\lambda_{i}(M_{i}(w,w_{0})-1+\xi_{i})-\sum_{i=1}^{n} \xi_{i}\eta_i=
	$$
	$$
	=\frac{1}{2}\Vert w\Vert^{2}-\sum_{i=1}^{n}\lambda_{i}(M_{i}(w,w_{0})-1)-\sum_{i=1}^{n}\xi_{i}(\lambda_{i}+\eta_{i}-C),
	$$
	
	где $\lambda=(\lambda_{1},\ \ldots,\ \lambda_{n})$ --- вектор переменных, двойственных к $w$; $\eta=(\eta_{1},\ \ldots,\ \eta_{n})$ --- вектор
	переменных, двойственных к $\xi$.
	
	Согласно теореме Куна-Таккера, задача эквивалентна двойственной задаче поиска седловой точки функции Лагранжа:
	$$
	\begin{cases}
		\mathcal{L}(w, w_{0}, \xi;\lambda,\eta)\rightarrow \underset{w,w_{0},\xi} \min  \underset{\lambda,\eta} \max; \\
		\xi_{i}\geq 0,\ \lambda_{i}\geq 0,\ \eta_{i}\geq 0,\ i=1,\ \ldots,\ n;\\
		\lambda_{i}=0\ либо M_{i}(w,\ w_{0})=1-\xi_{i},\ i=1,\ \ldots,\ n;\\
		\eta_{i}=0\ либо \xi_{i}=0,\ i=1,\ \ldots,\ \ell;
	\end{cases}
	$$
	
	В последних двух строках записаны условия дополняющей нежёсткоcти.
	
	\newpage
	
	Необходимым условием седловой точки функции Лагранжа является равенство
	нулю её производных. Отсюда получаются соотношения:
	$$
	\begin{cases}
		\frac{\partial}{\partial w}: & w = \sum\limits_{i=1}^{n}\lambda_i y_i x_i \\
		\frac{\partial}{\partial w_0}: & 0=\sum\limits_{i=1}^{n}\lambda_i y_i \\
		\frac{\partial}{\partial \xi_i}: & \lambda_i=C-\eta_i \\
	\end{cases}
	$$

	Из первого равенства следует, что искомый вектор весов $w$ является линейной комбинацией векторов обучающей выборки $x_i$, причём только тех, для которых $\lambda_i > 0$. Используя эти равенства, получаем
	$$
	\begin{cases}
		-\mathcal{L}(\lambda)=-\sum\limits_{i=1}^n\lambda_i+\frac{1}{2}\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\lambda_i\lambda_j y_i y_k \langle x_i,  x_j \rangle \rightarrow \min\limits_{\lambda} \\
		0 \leq \lambda_i \leq C, \forall i \\
		\sum\limits_{i=1}^{n}\lambda_i y_i=0 \\
	\end{cases}
	$$
	
	Здесь минимизируется квадратичный функционал, имеющий неотрицательно
	определённую квадратичную форму, следовательно, выпуклый. Область, определяемая ограничениями неравенствами и одним равенством, также выпуклая. Следовательно, данная двойственная задача имеет единственное решение. 
	
	Константу $C$ обычно выбирают по критерию скользящего контроля. Трудоемко, задачу приходится решать заново при каждом значении $C$. Если полагаем, что выборка почти линейно разделима, и лишь объекты-выбросы классифицируются неверно, то можно применить фильтрацию выбросов. 
	
	Уже показали, как вычисляеся $w$. Для определения порога $w_0$ достаточно взять произвольный опорный граничный вектор $x_i$ и выразить $w_0$ из равенства $w_{0}=\langle w, x_{i}\rangle-y_{i}$.
	
	В итоге алгоритм классификации представляется в следующем виде:
	
	\begin{center}
		$a(x)=$ sign ($\displaystyle \sum_{i=1}^{n}\lambda_{i}y_{i}\langle x_{i},\ x\rangle-w_{0})$
	\end{center} 
	
	Cуммирование идёт не по всей выборке, а только по опорным векторам, для которых $\lambda_i \neq 0$. Классификатор не изменится, если	все остальные объекты исключить из выборки. 
	
	Но ненулевыми $\lambda_I$ обладают не только опорные объекты, но и объекты-нарушители. Это недостаток SVM, т.к. ими часто оказываются шумовые выбросы, и построенное на них решающее правило опирается на шум. 
	
	\subsection{Ядра и спрямляющие пространства (The Kernel Trick)}
	
	Подход к решению проблемы линейной неразделимости. Переход от исходного пространства признаковых описаний объектов $X$ к новому пространству $H$ с помощью некоторого преобразования $\psi:X\rightarrow H$.  Пространство H должно быть наделено	скалярным произведением, в частности, подойдёт любое евклидово, а в общем случае и гильбертово.
	
	Функция $K:X\times X\rightarrow \mathbb{R}$ называется ядром (kernel function), если она	представима в виде $K(x,\ x')=\langle\psi(x), \psi(x')\rangle$ при некотором отображении $\psi:X\rightarrow H,$ где $H$ — пространство со скалярным произведением.
	
	Алгоритм зависит только от скалярных произведений объектов, но не от самих признаковых описаний. Скалярное произведение $\langle x,  x'\rangle$ можно формально заменить ядром $K(x,\ x')$.
	
	Функция $K(x,\ x')$ является ядром только тогда, когда она симметрична, $K(x,\ x')=K(x',\ x)$, и неотрицательно определена (теор. Мерсера)	
	$\int_{X}\int_{X} K(x,\ x') g(x) g(x')dx dx' \geq 0$ для любой функции $g:X\rightarrow \mathbb{R}$.
	
	Способы построения ядер:
	
	\begin{itemize}
		\item Произвольное скалярное произведение $K(x,\ x')=\langle x,  x'\rangle$;
		\item Константа $K(x,\ x')=1$ является ядром;
		\item Произведение ядер $K(x,\ x')=K_{1}(x,\ x')K_{2}(x,\ x')$ является ядром;
		\item Для любой функции $\psi$ : $X\rightarrow \mathbb{R}$ произведение $K(x,\ x')=\psi(x)\psi(x')$ является ядром.
		\item Линейная комбинация ядер с неотрицательными коэффициентами $K(x,\ x')= =\alpha_{1}K_{1}(x,\ x')+\alpha_{2}K_{2}(x,\ x')$ является ядром;
		\item Композиция произвольной функции  $\varphi$ : $X\rightarrow X$ и произвольного ядра $K_{0}$ является ядром: $K(x,\ x')=K_{0}(\varphi(x),\ \varphi(x'))$.
	\end{itemize}

	Наиболее часто используемые ядра: линейное ,полиномиальное, радиальное, сигмовидное.
	
	\vspace{1cm}
	
	\begin{figure}[!ht]
		%\vspace{-20mm} % <-- Go crazy here!
		\centering
		\includegraphics[width=\linewidth]{Kernel}
		\caption{Plot classification boundaries with different SVM Kernels}
		\label{5}
	\end{figure}

	\newpage
	

	\section{Метод стохастического градиента}
	
	Стохастический градиентный спуск - оптимизационный алгоритм, при котором градиент оптимизируемой функции считается на каждой итерации от случайно выбранного элемента выборки. Используем старые обозначения, дополнив, что $ a(x, \omega) $ --- семейство алгоритмов с параметром вектора весов $ \omega $.
	

	Стохастический градиентный спуск является модификацией градиентного спуска, и в случае линейного классификатора искомый алгоритм имеет вид:
	
	\begin{eqnarray}
	a(x, \omega) = \phi(\sum\limits_{j=1}^N \omega_jx^j - \omega_0),
	\end{eqnarray}
	
	где $\phi(z) $ - функция активации. 
	
	Решаемая задача:
	$$ Q(\omega) = \frac{1}{n}\sum\limits_{i=1}^{n}\mathcal{L}(a(x_i, \omega), y_i)\rightarrow\min\limits_{\omega}. $$
	
	Обновление весов:
	
	\begin{eqnarray}
	\omega^{(t+1)} = \omega^{(t)} - h\nabla Q(\omega^{(t)}).
	\end{eqnarray}
	
	Проблема GD --- чтобы определить новое приближение вектора весов необходимо вычислить градиент от каждого элемента выборки, что может сильно замедлять алгоритм.
	Идея ускорения заключается в использовании либо одного элемента (SGD), либо некоторой подвыборки (Batch GD) для получения нового приближения весов. 
	
	Веса, при подходе SGD, обновляются следующим образом:
	
	$$ \omega^{(t+1)} = \omega^{(t)} - h\nabla \mathcal{L}(a(x_i, \omega^{(t)}), y_i),$$ где $ i $ --- случайно выбранный индекс.
	
	Новый стохастический градиент должен быть несмещённой оценкой полного градиента (сходимость SGD обеспечивается несмещенностью). Т.к. направление изменения $ \omega $ будет определяться за $ O(1) $, подсчет $ Q $ на каждом шаге будет слишком дорогостоящим. Для ускорения оценки, будем использовать одну из рекуррентных формул:
	\begin{itemize}
		\item Среднее арифметическое: $ \overline Q_m = \frac{1}{m}\mathcal{L}(a(x_{i_m}, \omega^{(m)}), y_{i_m}) + (1 - \frac{1}{m}) \overline Q_{m-1}$;
		\item Экспоненциальное скользящее среднее: $ \overline Q_m = \lambda\mathcal{L}(a(x_{i_m}, \omega^{(m)}), y_{i_m}) + (1 - \lambda) \overline Q_{m-1}$, где $ \lambda $ --- темп забывания "предыстории" ряда.
	\end{itemize}
	
	Так как алгоритм итеративный, нужно задать начальные значения весов оптимизируемой модели. Существует несколько способов инициализации весов, например:
	
	\begin{itemize}
		\item $ \omega_0 = 0 $;
		\item $ \omega_0 = random(-\frac{1}{2n}, \frac{1}{2n}) $;
	\end{itemize}
	
	Достоинства: метод легко реализуется, функция потерь и семейство алгоритмов могут быть любыми, подходит для задач с большими данными, иногда можно получить решение даже не обработав всю выборку;
	
	Недостатки: проблемы с локальными экстремумами (для борьбы с этим используют технику "встряхивания коэффициентов" (jog of weights)); направление обновляется на основании получаемых в данный момент данных; алгоритм может не сходиться или сходиться слишком медленно.
	
	Альтернативы:
	\begin{itemize}
		\item Метод импульса --- запоминает $ \Delta\omega $ на каждой итерации и определяет следующее изменение в виде линейной комбинации градиента и предыдущего изменения;
		\item AdaGrad --- модификация SGD с отдельной для каждого параметра скоростью обучения;
		\item RMSProp --- это метод, в котором скорость обучения настраивается для каждого параметра. Идея заключается в делении скорости обучения для весов на скользящие средние значения недавних градиентов для этого веса;
		\item Adam --- ADAptive Momentum. Как правило, в этом алгоритме подбирают лишь один гиперпараметр --- learning rate. Требует хранения как параметров модели, так и градиентов, накопленного импульса и нормировочных констант. Достижение более быстрой (с точки зрения количества итераций/объема рассмотренных данных) сходимости требует больших объемов памяти. 
	\end{itemize}
		
	%\iffalse
	
	\newpage
	
	\section{Выбор модели}
	
	Обозначим алгоритм классификации, аппроксимирующий целевую зависимость на всем множестве $\mathbf{X}$ по обучающей выборке ${X}^n = (x_i, y_i)_{i = 1}^{n}$, как $a : X \rightarrow Y$. Задача --- найти модель, наилучшую по определенному критерию. Задаем функционал средней ошибки алгоритма как
	\begin{eqnarray}\label{error}  
		Q(a, {X}^n)=\frac{1}{n} \sum_{i = 1}^{n} \mathcal{L} (a, x_i). 
	\end{eqnarray}
	
	Функция потерь $\mathcal{L}$ характеризует величину ошибки алгоритма $a$ на объекте $x$. Пример такой функции; $\mathcal{L}(a, x) = [a(x) \neq y*$$(x)]$.
	
	\subsection{Критерии выбора модели. Скользящий контроль}
	
	Критерий выбора --- функционал $Q(\mu, {X}^n)$, характеризующий качество метода $\mu$. Так, метод минимизации эмпирического риска строит алгоритм с минимальным значением критерия
	\begin{eqnarray}\label{Min_error_criterion}  
		\mu ({X}^n) = \arg \min _{{a \in A}} Q(a, {X}^n). 
	\end{eqnarray}
	
	Скользящий контроль (cross-validation, CV) --- процедура эмпирического оценивания, с помощью которой "эмулируется" \ наличие тестовой выборки, которая не участвует в обучении, но для которой имеются метки класса. Разбиение выборки: ${X}^L = {X}^n \cup {X}^k$. 
	\begin{eqnarray}\label{CV}  
		CV (\mu, {X}^n) =\frac{1}{N} \sum_{n = 1}^{N} Q (\mu(X_{n}^{n}), X_{n}^{k}). 
	\end{eqnarray}
	
	Существует несколько вариантов скользящего контроля (Complete CV, leave-one-out CV, q-fold CV). Complete CV строится по всем $N = C_{L}^{K}$, вычислительно слишком сложен и применяется в теоретических исследования или если можно вывести удобную вычислительную формулу. На практике интересны другие 2 варианта. 

	Leave-one-out CV:
	\begin{eqnarray}\label{LOO}  
		LOO(\mu, X^L) =\frac{1}{L} \sum_{i = 1}^{L} Q (\mu(X^L \backslash \{x_i\}), \{x_i\}). 
	\end{eqnarray}
	
	Каждый объект участвует в контроле один раз, длина обучающих подвыборок на единицу меньше длины полной выборки. Обучать приходится $L$ раз, что тоже трудоемко.
	
	Q-fold CV --- случайное разбиение выборки на $q$ непересекающихся блоков одинаковой длины $l_1, ..., l_n$;$ X^L = X_{1}^{l_1} \cup \dots \cup  X_{q}^{l_q}$, $l_1 + \dots + l_q = L$. Блок по очереди становится контрольной подвыборкой, обучение по остальным q-1 блокам. Критерий определяется как средняя по всем блокам ошибка. 
	\begin{eqnarray}\label{Q-fold}  
		Q_{ext}(\mu, X^L) =\frac{1}{q} \sum_{n = 1}^{q} Q (\mu(X^L \backslash X_{n}^{l_n}), X_{n}^{l_n}). 
	\end{eqnarray}
	
	Для выбора оптимального метода рекомендуется использовать несколько разные критериев. Например, отбираем  несколько лучших методов по критерию, затем из них выбрать тот, для которого другой критерий принимает наименьшее значение.
	
		
	% \fi

\end{document}